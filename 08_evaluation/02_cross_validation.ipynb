{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c72a000",
   "metadata": {},
   "source": [
    "# 교차 검증 (Cross Validatain)\n",
    "- 모델을 더욱 신뢰성 있게 평가하는 방법\n",
    "- 데이터셋을 여러 개로 나누고, 각 부분이 한번씩 검증 데이터로 사용되도록 하는 방법\n",
    "- 훈련-검증을 반복하면서 학습을 진행\n",
    "- 과대적합 방지 효과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c466f6d4",
   "metadata": {},
   "source": [
    "### K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b620531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc84553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([50, 50, 50]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_input, iris_target = load_iris(return_X_y=True)\n",
    "# np.unique(iris_target, return_counts=True) → (array([0, 1, 2]), array([50, 50, 50], dtype=int64)) # 각 클래스의 데이터 개수 50개 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361b3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([40, 41, 39]))\n",
      "(array([0, 1, 2]), array([10,  9, 11]))\n",
      "------------------------------------------------------------------------------------------\n",
      "(array([0, 1, 2]), array([37, 40, 43]))\n",
      "(array([0, 1, 2]), array([13, 10,  7]))\n",
      "------------------------------------------------------------------------------------------\n",
      "(array([0, 1, 2]), array([38, 40, 42]))\n",
      "(array([0, 1, 2]), array([12, 10,  8]))\n",
      "------------------------------------------------------------------------------------------\n",
      "(array([0, 1, 2]), array([42, 40, 38]))\n",
      "(array([0, 1, 2]), array([ 8, 10, 12]))\n",
      "------------------------------------------------------------------------------------------\n",
      "(array([0, 1, 2]), array([43, 39, 38]))\n",
      "(array([0, 1, 2]), array([ 7, 11, 12]))\n",
      "------------------------------------------------------------------------------------------\n",
      "훈련별 정확도: [1.0, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667]\n",
      "분류모델 정확도: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 모델 생성\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "# 교차검증 KFold 객체 생성 : 데이터를 K(n_splits)개의 묶음으로 나눠주는 역할\n",
    "# - n_splits: 폴드의 개수, shuffle: 폴드로 나누기 전에 데이터를 섞을지 여부\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 교차검증 수행, 학습과 검증을 반복하면서 평가\n",
    "# k번 반복하면서 평가한 정확도를 저장할 배열\n",
    "cv_accuracy = [] # 평가 점수를 계속 쌓을 수 있게 빈배열을 초기화\n",
    "\n",
    "for train_index, val_index in kfold.split(iris_input):\n",
    "    X_train, y_train = iris_input[train_index], iris_target[train_index] # 학습 데이터, fancy indexing\n",
    "    X_val, y_val = iris_input[val_index], iris_target[val_index] # 검증 데이터\n",
    "\n",
    "    print(np.unique(y_train, return_counts=True))\n",
    "    print(np.unique(y_val, return_counts=True))\n",
    "    print('---'*30)\n",
    "\n",
    "    # oversampling 작동 원리\n",
    "    # under sampling 작동 원리 \n",
    "\n",
    "    # Sampling 편향을 일으킬 수도 있다.\n",
    "    # 예) 클래스 0, 1, 2 데이터 개수가 50개씩 동일하지 않은 경우\n",
    "    # iris데이터는 50개씩 동일한 학습 데이터\n",
    "\n",
    "\n",
    "    # 모델 학습\n",
    "    lr_clf.fit(X_train, y_train)              # 모델 학습\n",
    "    y_pred = lr_clf.predict(X_val)            # 검증데이터로 예측한 결과\n",
    "    acc_score = accuracy_score(y_val, y_pred) # 실제값, 예측값을 통한 정확도 계산\n",
    "    cv_accuracy.append(acc_score)             # cv_accuracy 배열에 정확도 저장\n",
    "\n",
    "print(\"훈련별 정확도:\", cv_accuracy)\n",
    "print(\"분류모델 정확도:\", np.mean(cv_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9795bb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_index: [  0   1   2   3   4   5   6   7   8  10  11  13  14  15  16  17  20  21\n",
      "  22  23  24  25  27  28  32  33  34  35  37  38  39  40  41  42  43  44\n",
      "  46  47  48  49  50  51  52  53  54  57  58  59  60  61  62  63  65  66\n",
      "  67  70  71  72  74  75  77  79  80  81  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103 105 106 107 109 111\n",
      " 112 113 114 115 116 117 119 120 121 122 123 124 125 126 129 130 133 134\n",
      " 135 136 137 138 139 140 142 144 146 147 148 149],\n",
      " val_index: [  9  12  18  19  26  29  30  31  36  45  55  56  64  68  69  73  76  78\n",
      "  82 104 108 110 118 127 128 131 132 141 143 145]\n",
      "------------------------------------------------------------------------------------------\n",
      "train_index: [  1   2   3   5   6   7   8   9  12  13  14  17  18  19  20  21  23  24\n",
      "  25  26  29  30  31  33  34  35  36  37  38  39  41  43  45  46  47  48\n",
      "  49  50  52  53  54  55  56  57  58  59  61  62  63  64  68  69  70  71\n",
      "  72  73  74  76  77  78  79  80  82  83  84  87  88  89  90  91  92  93\n",
      "  94  95  97  98  99 100 101 102 103 104 106 107 108 110 111 112 113 114\n",
      " 115 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 134\n",
      " 135 136 138 139 140 141 143 144 145 147 148 149],\n",
      " val_index: [  0   4  10  11  15  16  22  27  28  32  40  42  44  51  60  65  66  67\n",
      "  75  81  85  86  96 105 109 122 133 137 142 146]\n",
      "------------------------------------------------------------------------------------------\n",
      "train_index: [  0   1   2   3   4   6   8   9  10  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  26  27  28  29  30  31  32  36  37  38  40  41  42  44  45\n",
      "  46  48  50  51  52  54  55  56  57  58  59  60  61  63  64  65  66  67\n",
      "  68  69  71  72  73  74  75  76  78  79  81  82  83  85  86  87  88  89\n",
      "  90  91  92  96  98  99 100 102 103 104 105 106 107 108 109 110 112 115\n",
      " 116 118 119 120 121 122 124 125 126 127 128 129 130 131 132 133 134 135\n",
      " 136 137 139 140 141 142 143 144 145 146 147 149],\n",
      " val_index: [  5   7  23  24  25  33  34  35  39  43  47  49  53  62  70  77  80  84\n",
      "  93  94  95  97 101 111 113 114 117 123 138 148]\n",
      "------------------------------------------------------------------------------------------\n",
      "train_index: [  0   1   4   5   7   9  10  11  12  14  15  16  18  19  20  21  22  23\n",
      "  24  25  26  27  28  29  30  31  32  33  34  35  36  37  39  40  41  42\n",
      "  43  44  45  47  48  49  51  52  53  55  56  57  58  60  62  64  65  66\n",
      "  67  68  69  70  71  73  74  75  76  77  78  80  81  82  84  85  86  87\n",
      "  88  90  91  92  93  94  95  96  97  99 101 102 103 104 105 106 107 108\n",
      " 109 110 111 113 114 116 117 118 121 122 123 124 127 128 129 130 131 132\n",
      " 133 137 138 140 141 142 143 144 145 146 148 149],\n",
      " val_index: [  2   3   6   8  13  17  38  46  50  54  59  61  63  72  79  83  89  98\n",
      " 100 112 115 119 120 125 126 134 135 136 139 147]\n",
      "------------------------------------------------------------------------------------------\n",
      "train_index: [  0   2   3   4   5   6   7   8   9  10  11  12  13  15  16  17  18  19\n",
      "  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  38  39  40\n",
      "  42  43  44  45  46  47  49  50  51  53  54  55  56  59  60  61  62  63\n",
      "  64  65  66  67  68  69  70  72  73  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  89  93  94  95  96  97  98 100 101 104 105 108 109 110 111\n",
      " 112 113 114 115 117 118 119 120 122 123 125 126 127 128 131 132 133 134\n",
      " 135 136 137 138 139 141 142 143 145 146 147 148],\n",
      " val_index: [  1  14  20  21  37  41  48  52  57  58  71  74  87  88  90  91  92  99\n",
      " 102 103 106 107 116 121 124 129 130 140 144 149]\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for train_index, val_index in kfold.split(iris_input):\n",
    "    print(f'train_index: {train_index},\\n val_index: {val_index}\\n'+'---'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f6a8dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_input.shape, iris_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb00ab1",
   "metadata": {},
   "source": [
    "### **StratifiedKFold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a964c1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([40, 40, 40]))\n",
      "(array([0, 1, 2]), array([10, 10, 10]))\n",
      "------------------------------------------------------------------------------------------\n",
      "(array([0, 1, 2]), array([40, 40, 40]))\n",
      "(array([0, 1, 2]), array([10, 10, 10]))\n",
      "------------------------------------------------------------------------------------------\n",
      "(array([0, 1, 2]), array([40, 40, 40]))\n",
      "(array([0, 1, 2]), array([10, 10, 10]))\n",
      "------------------------------------------------------------------------------------------\n",
      "(array([0, 1, 2]), array([40, 40, 40]))\n",
      "(array([0, 1, 2]), array([10, 10, 10]))\n",
      "------------------------------------------------------------------------------------------\n",
      "(array([0, 1, 2]), array([40, 40, 40]))\n",
      "(array([0, 1, 2]), array([10, 10, 10]))\n",
      "------------------------------------------------------------------------------------------\n",
      "훈련별 정확도: [1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9333333333333333]\n",
      "분류모델 정확도: 0.9666666666666668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# StratifiedKFold : 분류 모델에서 주로 사용\n",
    "# 데이터 분할 시 각 클래스의 데이터 비율을 유지하는 방법\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 모델 생성\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "# 교차검증 StratifiedKFold 객체 생성 : 데이터를 K(n_splits)개의 묶음으로 나눠주는 역할, 각 폴드에서 각 클래스의 데이터 비율을 유지\n",
    "# - n_splits: 폴드의 개수, shuffle: 폴드로 나누기 전에 데이터를 섞을지 여부\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# k번 반복하면서 평가한 정확도를 저장할 배열\n",
    "cv_accuracy = [] # 평가 점수를 계속 쌓을 수 있게 빈배열을 초기화\n",
    "                                                                               # target 데이터의 label을 전달해야 비율을 유지할 수 있음\n",
    "for train_index, val_index in stratified_kfold.split(iris_input, iris_target): # iris_input, iris_target 데이터를 넣어줘야 함\n",
    "    X_train, y_train = iris_input[train_index], iris_target[train_index]       # 학습 데이터, fancy indexing\n",
    "    X_val, y_val = iris_input[val_index], iris_target[val_index]               # 검증 데이터\n",
    "\n",
    "    print(np.unique(y_train, return_counts=True))\n",
    "    print(np.unique(y_val, return_counts=True))\n",
    "    print('---'*30)\n",
    "\n",
    "    # KFold 는 Sampling 편향을 일으킬 수도 있다. → StratifiedKFold 는 비율을 유지하므로 편향을 줄일 수 있다.\n",
    "    # 예) 클래스 0, 1, 2 데이터 개수가 50개씩 동일하지 않은 경우\n",
    "    # iris데이터는 50개씩 동일한 학습 데이터\n",
    "\n",
    "\n",
    "    # 모델 학습\n",
    "    lr_clf.fit(X_train, y_train)              # 모델 학습\n",
    "    y_pred = lr_clf.predict(X_val)            # 검증데이터로 예측한 결과\n",
    "    acc_score = accuracy_score(y_val, y_pred) # 실제값, 예측값을 통한 정확도 계산\n",
    "    cv_accuracy.append(acc_score)             # cv_accuracy 배열에 정확도 저장\n",
    "\n",
    "print(\"훈련별 정확도:\", cv_accuracy)\n",
    "print(\"분류모델 정확도:\", np.mean(cv_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10495450",
   "metadata": {},
   "source": [
    "### cross_val_score\n",
    "- 교차검증을 통해 모델 성능을 평가하는 함수\n",
    "- 내부적으로 지정한 횟수만큼 학습/검증을 나누어 반복 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f5ca58",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c307672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련별 정확도: [0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
      "모델 평균 정확도: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# 첫번째 인자 : 모델\n",
    "# 두번째 인자 : 특성 데이터\n",
    "# 세번째 인자 : 라벨 데이터\n",
    "# 네번째 인자 : 반복횟수(내부적으로 KFold 객체를 사용) → 데이터를 알아서 나눠서, 학습을 하고 평가를 한다. (나눠지는 기준 : KFold 객체)\n",
    "    # cv : 반복 횟수 → int, BaseCrossValidator 객체, Iterable[int] → 전달 가능 → StratifiedKFold 객체 전달 가능\n",
    "        \n",
    "        # For int/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used.\n",
    "        # In all other cases, KFold is used. These splitters are instantiated with shuffle=False so the splits will be the same across calls.\n",
    "        # Refer User Guide for the various cross-validation strategies that can be used here.\n",
    "\n",
    "        # 분류 문제에서는 라벨 데이터가 이진 또는 다중 클래스인 경우 StratifiedKFold 사용\n",
    "        # 입력 의 None경우, 추정기가 분류기이고 y이진 또는 다중 클래스이면 가 StratifiedKFold사용됩니다.\n",
    "        # 다른 모든 경우에는 KFold가 사용됩니다. 이러한 분할기는 로 인스턴스화되므로 shuffle=False호출 전체에서 분할이 동일합니다.\n",
    "\n",
    "\n",
    "# scoring : 평가 지표(정확도, 정밀도, 재현율, F1-score, 등) → 문자열, callable, None → 전달 가능\n",
    "    # accuracy(default), precision, recall, f1, roc_auc, 등\n",
    "    # 전달되지 않으면 모델의 평가 지표를 사용\n",
    "    # 전달되는 값은 모델의 평가 지표를 사용\n",
    "# 반환값 : 반복할 훈련별 검증 점수 '배열' \n",
    "    # 각 반복에서 얻은 정확도가 배열로 반환된다.\n",
    "# 예) 5개의 폴드로 나누어 5번 반복 평가 → 5개의 정확도 배열 반환\n",
    "\n",
    "scores = cross_val_score(lr_clf, iris_input, iris_target, cv=5, scoring='accuracy') # 모델, 데이터, 반복 횟수, 평가 지표(정확도)\n",
    "\n",
    "print('훈련별 정확도:', scores)\n",
    "print('모델 평균 정확도:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b137a59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.04074907, 0.01844144, 0.        , 0.        , 0.00614572]),\n",
       " 'score_time': array([0.00201201, 0.00050521, 0.01518726, 0.01505351, 0.00989747]),\n",
       " 'test_accuracy': array([0.96666667, 1.        , 0.93333333, 0.96666667, 1.        ]),\n",
       " 'train_accuracy': array([0.96666667, 0.96666667, 0.98333333, 0.98333333, 0.975     ]),\n",
       " 'test_f1_macro': array([0.96658312, 1.        , 0.93265993, 0.96658312, 1.        ]),\n",
       " 'train_f1_macro': array([0.96664582, 0.96664582, 0.98333333, 0.98332291, 0.97499609])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "# 모델 객체\n",
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# cross_validate 함수는 여러 평가 지표를 한번에 사용할 수 있다. → 다중 평가지표\n",
    "# f1_macro : 각 클래스의 평균 f1-score, 이진 분류 모델에서 사용\n",
    "# return_train_score : 훈련 데이터로 평가한 점수도 반환\n",
    "\n",
    "scores = cross_validate(lr_clf, iris_input, iris_target, cv=5, scoring=['accuracy', 'f1_macro'], return_train_score=True)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f8d97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFittedError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mlr_clf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43miris_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:375\u001b[39m, in \u001b[36mLinearClassifierMixin.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    362\u001b[39m \u001b[33;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[32m    363\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    372\u001b[39m \u001b[33;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    374\u001b[39m xp, _ = get_namespace(X)\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores.shape) == \u001b[32m1\u001b[39m:\n\u001b[32m    377\u001b[39m     indices = xp.astype(scores > \u001b[32m0\u001b[39m, indexing_dtype(xp))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:349\u001b[39m, in \u001b[36mLinearClassifierMixin.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    331\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[33;03m    Predict confidence scores for samples.\u001b[39;00m\n\u001b[32m    333\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    347\u001b[39m \u001b[33;03m        this class would be predicted.\u001b[39;00m\n\u001b[32m    348\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m     xp, _ = get_namespace(X)\n\u001b[32m    352\u001b[39m     X = validate_data(\u001b[38;5;28mself\u001b[39m, X, accept_sparse=\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m, reset=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:1754\u001b[39m, in \u001b[36mcheck_is_fitted\u001b[39m\u001b[34m(estimator, attributes, msg, all_or_any)\u001b[39m\n\u001b[32m   1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1753\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[32m-> \u001b[39m\u001b[32m1754\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg % {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator).\u001b[34m__name__\u001b[39m})\n",
      "\u001b[31mNotFittedError\u001b[39m: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "lr_clf.predict(iris_input)\n",
    "# NotFittedError: This LogisticRegression instance is not fitted yet.\n",
    "\n",
    "# cross_val_score, cross_validate 는 모델 학습을 하지 않는다.\n",
    "# 내부적으로는 학습을 해서 평가를 하는 것이지만, 실제 학습된 모델을 반환하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9493011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
